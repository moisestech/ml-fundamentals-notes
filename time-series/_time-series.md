# Time Series

## [ðŸŽ“ Time Series Forecasting, Lesson 8, Udacity, UD187, Intro to TensorFlow for Deep Learning](https://classroom.udacity.com/courses/ud187/lessons/6d543d5c-6b18-4ecf-9f0f-3fd034acd2cc/concepts/1b8a6e07-b2d3-4e4c-904c-822217cd8335)

---

## **1. Meet Your Instructor**

- AurÃ©lien GÃ©ron

- Meet Your Instructor
- AurÃ©lien GÃ©ron is a Machine Learning consultant, author of the best-selling O'Reilly book "Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow".
  - A former Googler, he led YouTube's video classification team from 2013 to 2016.
  - He was also a founder and CTO of Wifirst from 2002 to 2012, a leading Wireless ISP in France.
  - Before this he worked as a consultant in a variety of domains: finance (JP Morgan and SociÃ©tÃ© GÃ©nÃ©rale), defense (Canada's DOD), and healthcare (blood transfusion).
  - He also published a few technical books (on C++, WiFi, and Internet architectures), and he is a lecturer at the Dauphine University in Paris.
  - He currently lives in New Zealand with his wife and 3 children.

---

## **2. Introduction**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/-_tBhZkkNMA)

---

## **3. Applications**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/-nEEy6h6AcE)

---

## **4. Common Patterns**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/RfjM-FlUa7M)

---

## **5. Colab: Common Patterns**

### Colab Notebook

- To access the Colab Notebook, login to your Google account and click on the link below:

- [Common Patterns](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l08c01_common_patterns.ipynb)

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/usSx5o9UXJE)

### Note

- Since neural networks rely on stochasticity (i.e. randomness) to initialize their parameters and gradient descent selects random batches of training data at each iteration, is perfectly normal if the outputs you see when you run the Colabs are slightly different from those shown in the video.

---

## **6. Forecasting**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/JTzUd8RdYWc)

---

## **7. Colab: Naive Forecasting**

### Colab Notebook 2

- To access the Colab Notebook, login to your Google account and click on the link below:

- [Naive Forecasting](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l08c02_naive_forecasting.ipynb)

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/UGd8ufUOoOI)

### Note 2

- Since neural networks rely on stochasticity (i.e. randomness) to initialize their parameters and gradient descent selects random batches of training data at each iteration, is perfectly normal if the outputs you see when you run the Colabs are slightly different from those shown in the video.

---

## **8. Metrics**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/vEozDGPwQ7c)

---

## **9. Colab: Moving Average**

### Colab Notebook 3

- To access the Colab Notebook, login to your Google account and click on the link below:

- [Moving Average](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l08c03_moving_average.ipynb)

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/SV2D-ZHi36g)

### Note 3

- Since neural networks rely on stochasticity (i.e. randomness) to initialize their parameters and gradient descent selects random batches of training data at each iteration, is perfectly normal if the outputs you see when you run the Colabs are slightly different from those shown in the video.

---

## **10. Time Windows**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/lAzlrxfMoJU)

---

## **11. Colab: Time Windows**

### Colab Notebook 4

- To access the Colab Notebook, login to your Google account and click on the link below:

- [Time Windows](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l08c04_time_windows.ipynb)

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/pNW2lHQY0mw)

### Note 4

- Since neural networks rely on stochasticity (i.e. randomness) to initialize their parameters and gradient descent selects random batches of training data at each iteration, is perfectly normal if the outputs you see when you run the Colabs are slightly different from those shown in the video.

---

## **12. Forecasting with Machine Learning**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/crgkWcxBsLU)

---

## **13. Colab: Forecasting with Machine Learning**

### Colab Notebook 5

- To access the Colab Notebook, login to your Google account and click on the link below:

- Forecasting with Machine Learning

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/q3wWjtCsaLc)

### Note 5

- Since neural networks rely on stochasticity (i.e. randomness) to initialize their parameters and gradient descent selects random batches of training data at each iteration, is perfectly normal if the outputs you see when you run the Colabs are slightly different from those shown in the video.

---

## **14. RNNs**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/tln6r6Ks0P0)

---

## **15. Recurrent Layer**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/gREXBl-SnLM)

---

## **16. Forecasting with an RNN**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/b3bT4Vrxi2Y)

---

## **17. Back Propagation Through Time**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/SX1384XU7nE)

---

## **18. Colab: Forecasting with RNNs**

### Colab Notebook 6

- To access the Colab Notebook, login to your Google account and click on the link below:

- [Forecasting with RNNs](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l08c06_forecasting_with_rnn.ipynb)

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/LD-nnTpH3ow)

### Note 6

- Since neural networks rely on stochasticity (i.e. randomness) to initialize their parameters and gradient descent selects random batches of training data at each iteration, is perfectly normal if the outputs you see when you run the Colabs are slightly different from those shown in the video.

---

## **19. Stateless and Stateful RNNs**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/vLBIJ4iVMbo)

---

## **20. Implementing a Stateful RNN**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/BJuUmlzR3vo)

- **NOTE**: In the video, at 2:28, AurÃ©lien said "we get a mean absolute error of about 4.7". It should be "we get a mean absolute error of about 6.3".

---

## **21. Colab: Forecasting with Stateful RNNs**

### Colab Notebook 7

- To access the Colab Notebook, login to your Google account and click on the link below:

- [Forecasting With Stateful RNNs](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l08c07_forecasting_with_stateful_rnn.ipynb)

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/0ENiILqASCc)

### Note 7

- Since neural networks rely on stochasticity (i.e. randomness) to initialize their parameters and gradient descent selects random batches of training data at each iteration, is perfectly normal if the outputs you see when you run the Colabs are slightly different from those shown in the video.

---

## **22. LSTM Cells**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/XymI5lluJeU)

---

## **23. Implementing an LSTM**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/c8ZPubcl17w)

---

## **24. Colab: Forecasting with LSTM**

### Colab Notebook 8

- To access the Colab Notebook, login to your Google account and click on the link below:

- [Forecasting with LSTM](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l08c08_forecasting_with_lstm.ipynb)

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/XymI5lluJeU)

### Note 8

- Since neural networks rely on stochasticity (i.e. randomness) to initialize their parameters and gradient descent selects random batches of training data at each iteration, is perfectly normal if the outputs you see when you run the Colabs are slightly different from those shown in the video.

---

## **25. CNNs**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/CG2V--A7Ebk)

---

## **26. Padding**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/4aAQ5x73r9M)

---

## **27. Stride**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/HIHopzuLDsI)

---

## **28. Kernels**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/cg1-ytwBfOk)

---

## **29. WaveNet**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/VSU33wFHb0o)

---

## **30. Colab: Forecasting with CNNs**

### Colab Notebook 9

- To access the Colab Notebook, login to your Google account and click on the link below:

- [Forecasting with CNNs](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l08c09_forecasting_with_cnn.ipynb)

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/YUEbnm8M3-c)

### Note 9

- Since neural networks rely on stochasticity (i.e. randomness) to initialize their parameters and gradient descent selects random batches of training data at each iteration, is perfectly normal if the outputs you see when you run the Colabs are slightly different from those shown in the video.

---

## **31. Outro**

ðŸŽ¥ [Udacity, Video Link](https://youtu.be/iRoUs-KdQAg)

### Further Your Learning

- If you want to learn about other techniques for Time Series Forecasting, check our Free course by Tony Moses here on Udacity:

- [Time Series Forecasting](https://www.udacity.com/course/time-series-forecasting--ud980)

---

## Foam Related Links

- [[_deep-learning]]
