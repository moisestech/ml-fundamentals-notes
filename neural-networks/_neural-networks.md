# Neural Networks

---

**1. Introduction**

---

**2. Classification Problems 1**

---

**3. Classification Problems 2**
**4. Linear Boundaries**
**5. Higher Dimensions**
**6. Perceptrons**
**7. Why "Neural Networks"?**
**8. Perceptrons as Logical Operators**
**9. Perceptron Trick**
**10. Perceptron Algorithm**
**11. Non-Linear Regions**
**12. Error Functions**
**13. Log-loss Error Function**
**14. Discrete vs Continuous**
**15. Softmax**
**16. One-Hot Encoding**
**17. Maximum Likelihood**
**18. Maximizing Probabilities**
**19. Cross-Entropy 1**
**20. Cross-Entropy 2**
**21. Multi-Class Cross Entropy**
**22. Logistic Regression**
**23. Gradient Descent**
**24. Logistic Regression Algorithm**
**25. Pre-Notebook: Gradient Descent**
**26. Notebook: Gradient Descent**
**27. Perceptron vs Gradient Descent**
**28. Continuous Perceptrons**
**29. Non-linear Data**
**30. Non-Linear Models**
**31. Neural Network Architecture**
**32. Feedforward**
**33. Backpropagation**
**34. Pre-Notebook: Analyzing Student Data**
**35. Notebook: Analyzing Student Data**
**36. Training Optimization**
**37. Testing**
**38. Overfitting and Underfitting**
**39. Early Stopping**
**40. Regularization**
**41. Regularization 2**
**42. Dropout**
**43. Local Minima**
**44. Random Restart**
**45. Vanishing Gradient**
**46. Other Activation Functions**
**47. Batch vs Stochastic Gradient Descent**
**48. Learning Rate Decay**
**49. Momentum**
**50. Error Functions Around the World**
